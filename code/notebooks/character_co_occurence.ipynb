{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "#import nltk\n",
    "import timecorr as tc\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will be the file that feature extractor notebook generates for each script\n",
    "#out_fn = '/Users/vassiki/Desktop/narrative_complexity/code/notebooks/annotations_with_char_embeddings.csv'\n",
    "out_fn = '/Users/vassiki/Desktop/narrative_complexity/code/notebooks/annotations.csv'\n",
    "out_df = pd.read_csv(out_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chars_from_df(out_df):   \n",
    "    \"\"\"\n",
    "    Function to clean up unique list of characters, will be redundant after\n",
    "    the feature extraction notebook is updated\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    out_df: output csv for each script with segmented events as rows\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    characters: 2d list of unique characters in each event\n",
    "    \"\"\"\n",
    "    characters = []\n",
    "    for row in range(out_df.shape[0]):\n",
    "    \n",
    "        character_per_event = eval(out_df.loc[row, 'characters'])\n",
    "        unique_chars_events = character_per_event.keys()\n",
    "        chars_ev = [' '.join(c.split()) for c in list(unique_chars_events)]\n",
    "        first_name = [c.split(' ')[0] for c in chars_ev]\n",
    "        unique_first = list(dict.fromkeys(first_name))\n",
    "        # pos tag\n",
    "        #pos_tag_names = nltk.pos_tag(unique_first)\n",
    "        #noun_names = [n[0] for n in pos_tag_names if 'VB' not in n[1]]\n",
    "\n",
    "        characters.append(unique_first)\n",
    "    return characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cooccurence_matrix_one_event(characters, event_num=0):\n",
    "    \"\"\"\n",
    "    Function to create cooccurence matrix for all characters in an event.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    characters: 2d list of unique characters in each event\n",
    "    event_num: default 0, row number of event to return cooccurence matrix for\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    co_occurence_df: unique char by unique char dataframe with tallies\n",
    "                        for character cooccurences\n",
    "    \"\"\"\n",
    "    chars = list(dict.fromkeys(sum(characters,[])))\n",
    "    total_array_size = len(chars)\n",
    "    co_occurence_array = np.zeros((total_array_size, total_array_size))\n",
    "    co_occurence_df = pd.DataFrame(co_occurence_array, columns = chars, index=chars)\n",
    "    #all_pairs = list(itertools.combinations(characters[event_num], 2))\n",
    "    all_pairs = list(itertools.permutations(characters[event_num], 2))\n",
    "    for pair in all_pairs:\n",
    "        co_occurence_df.loc[pair[0], pair[1]] += 1\n",
    "    return co_occurence_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cooccurence_matrix_all_events(characters):\n",
    "    \"\"\"\n",
    "    Function to create cooccurence matrix across all events\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    characters: 2d list of unique characters in each event\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    co_occurence_df: character by character cooccurence matrix across\n",
    "                        all events\n",
    "    \"\"\"\n",
    "    chars = list(dict.fromkeys(sum(characters,[])))\n",
    "    total_array_size = len(chars)\n",
    "    co_occurence_array = np.zeros((total_array_size, total_array_size))\n",
    "    co_occurence_df = pd.DataFrame(co_occurence_array, columns = chars, index=chars)\n",
    "    for event_chars in range(len(characters)):\n",
    "        #all_pairs = list(itertools.combinations(characters[event_chars], 2))\n",
    "        all_pairs = list(itertools.permutations(characters[event_chars], 2))\n",
    "        for pair in all_pairs:\n",
    "            co_occurence_df.loc[pair[0], pair[1]] += 1\n",
    "    return co_occurence_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_one_event_cooccurence(fn, chars, num=0):\n",
    "    \"\"\"\n",
    "    Function to plot each event's cooccurence matrix\n",
    "    \n",
    "    Parameters:\n",
    "    fn: filename to save the co-occurence plot with\n",
    "    chars: 2d list of unique characters in each event \n",
    "    num: default 0, event number\n",
    "    \"\"\"\n",
    "    cdf  = get_cooccurence_matrix_one_event(chars, num)\n",
    "    l = list(cdf.columns)\n",
    "    plt.figure(figsize=(20,15))\n",
    "    sns.heatmap(cdf, xticklabels=l, yticklabels=l)\n",
    "    plt.savefig(fn, bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_events_cooccurence(fn, chars):\n",
    "    \"\"\"\n",
    "    Function to plot cooccurence matrix across all events\n",
    "    \n",
    "    Parameters:\n",
    "    fn: filename to save the co-occurence plot with\n",
    "    chars: 2d list of unique characters in each event\n",
    "    \"\"\"    \n",
    "    cca = get_cooccurence_matrix_all_events(chars)\n",
    "    labels = list(cca.columns)\n",
    "    plt.figure(figsize=(20,15))\n",
    "    sns.heatmap(cca, xticklabels=labels, yticklabels=labels)\n",
    "    plt.savefig(fn, bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate plot for all events\n",
    "characters = get_chars_from_df(out_df)\n",
    "root_dir = '/Users/vassiki/Desktop/narrative_complexity/notebooks/figures/'\n",
    "fn = os.path.join(root_dir, 'character_occurence.png')\n",
    "plot_all_events_cooccurence(fn, characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate plot for one event at a time\n",
    "characters = get_chars_from_df(out_df)\n",
    "root_dir = '/Users/vassiki/Desktop/narrative_complexity/notebooks/figures/'\n",
    "for event_num in range(len(characters)):\n",
    "    fn = os.path.join(root_dir, 'character_occurence_event_{0}.png'.format(event_num))\n",
    "    plot_one_event_cooccurence(fn, characters, event_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `convert -delay 10 -loop 0 *event*.png cooccurence.gif` in bash to generate gif from all events from the figures subdirectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toy example\n",
    "all_elements = np.arange(10)\n",
    "elements_in_events = []\n",
    "num_events = 20\n",
    "for ev in range(num_events):\n",
    "    elems_this_event = np.random.choice(5, np.random.randint(1,5, size=1), replace=False)\n",
    "    elements_in_events.append(list(elems_this_event))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cdf = get_cooccurence_matrix_all_events(elements_in_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = all_cdf.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_check_symmetric(a, tol=1e-8):\n",
    "    return np.all(np.abs(a-a.T) < tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_symmetric(mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired my Mark's talk, implementing Correspondence Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/elena-sharova/correspondence_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = get_chars_from_df(out_df)\n",
    "count_df = get_cooccurence_matrix_all_events(characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = count_df.gt(10)\n",
    "at= count_df.loc[m.any(axis=1), m.any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleCrosstab = at.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing chi-squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grandTotal = np.sum(sampleCrosstab)\n",
    "correspondenceMatrix = np.divide(sampleCrosstab,grandTotal)\n",
    "rowTotals = np.sum(correspondenceMatrix, axis=1)\n",
    "columnTotals = np.sum(correspondenceMatrix, axis=0)\n",
    "independenceModel = np.outer(rowTotals, columnTotals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chiSquaredStatistic = grandTotal*np.sum(np.square(correspondenceMatrix-independenceModel)/independenceModel)\n",
    "print(chiSquaredStatistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick check - compare to scipy Chi-Squared test\n",
    "from scipy.stats import chi2_contingency\n",
    "statistic, prob, dof, ex = chi2_contingency(sampleCrosstab)\n",
    "print(statistic)\n",
    "print(np.round(prob, decimals=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correspondence_analysis(sampleCrosstab):\n",
    "    grandTotal = np.sum(sampleCrosstab)\n",
    "    correspondenceMatrix = np.divide(sampleCrosstab,grandTotal)\n",
    "    rowTotals = np.sum(correspondenceMatrix, axis=1)\n",
    "    columnTotals = np.sum(correspondenceMatrix, axis=0)\n",
    "    independenceModel = np.outer(rowTotals, columnTotals)\n",
    "    chiSquaredStatistic = grandTotal*np.sum(np.square(correspondenceMatrix-independenceModel)/independenceModel)\n",
    "    print('Chi Squared for this matrix is {0}'.format(chiSquaredStatistic))\n",
    "    # pre-calculate normalised rows\n",
    "    norm_correspondenceMatrix = np.divide(correspondenceMatrix,rowTotals[:, None])\n",
    "\n",
    "    chiSquaredDistances = np.zeros((correspondenceMatrix.shape[0],correspondenceMatrix.shape[0]))\n",
    "\n",
    "    norm_columnTotals = np.sum(norm_correspondenceMatrix, axis=0)\n",
    "    for row in range(correspondenceMatrix.shape[0]):\n",
    "        chiSquaredDistances[row]=np.sqrt(np.sum(np.square(norm_correspondenceMatrix\n",
    "                                                        -norm_correspondenceMatrix[row])/columnTotals, axis=1))\n",
    "\n",
    "\n",
    "    standardizedResiduals = np.divide((correspondenceMatrix-independenceModel),np.sqrt(independenceModel))\n",
    "\n",
    "    u,s,vh = np.linalg.svd(standardizedResiduals, full_matrices=False)\n",
    "\n",
    "    deltaR = np.diag(np.divide(1.0,np.sqrt(rowTotals)))\n",
    "\n",
    "    rowScores=np.dot(np.dot(deltaR,u),np.diag(s))\n",
    "    return rowScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rowScores = correspondence_analysis(sampleCrosstab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFirstTwoComponents = pd.DataFrame(data=[l[0:2] for l in rowScores], columns=['X', 'Y'], index=at.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(data=dfFirstTwoComponents,x='X', y='Y', hue=at.columns)\n",
    "ax.axhline(y=0, color='k')\n",
    "ax.axvline(x=0, color='k')\n",
    "ax.get_legend().set_visible(False)\n",
    "\n",
    "for label in at.columns:\n",
    "    plt.annotate(label, \n",
    "                 (dfFirstTwoComponents.loc[label,:]['X'],\n",
    "                  dfFirstTwoComponents.loc[label,:]['Y']),\n",
    "                 horizontalalignment='center', verticalalignment='center',size=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFirstTwoComponents['group'] = list(dfFirstTwoComponents.index)\n",
    "dfFirstTwoComponents['colors'] = ['#e6194b', '#3cb44b', '#ffe119', '#4363d8', '#f58231', '#911eb4', '#46f0f0', '#f032e6', '#bcf60c', '#fabebe', '#008080', '#000000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "fig = plt.figure(figsize = (12,8))\n",
    "#plt.figure(figsize = (12,8))\n",
    "ax = sns.scatterplot(dfFirstTwoComponents['X'], dfFirstTwoComponents['Y'])\n",
    "\n",
    "for line in range(0,dfFirstTwoComponents.shape[0]):\n",
    "     ax.text(dfFirstTwoComponents.X[line], dfFirstTwoComponents.Y[line], dfFirstTwoComponents.group[line], horizontalalignment='center', size='large', color= dfFirstTwoComponents.colors[line])\n",
    "        \n",
    "fig.savefig('character2d.png', bbox_inches=\"tight\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('characters_2d.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Character co-occurrence matrix weighted by number of mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chars_from_df(out_df):   \n",
    "    \"\"\"\n",
    "    Function to clean up unique list of characters, will be redundant after\n",
    "    the feature extraction notebook is updated\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    out_df: output csv for each script with segmented events as rows\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    characters: 2d list of unique characters in each event\n",
    "    \"\"\"\n",
    "    characters = []\n",
    "    for row in range(out_df.shape[0]):\n",
    "    \n",
    "        character_per_event = eval(out_df.loc[row, 'characters'])\n",
    "        vals = {key: character_per_event[key] for key in character_per_event}\n",
    "        characters.append(vals)\n",
    "    return characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_by_char_all_events(out_df):\n",
    "    char_event_dict = get_chars_from_df(out_df)\n",
    "    row_length = out_df.shape[0]\n",
    "    c = [list(val.keys()) for val in char_event_dict]\n",
    "    chars = list(dict.fromkeys(sum(c,[])))\n",
    "    col_length = len(chars)\n",
    "    print('We have {0} events and {1} characters'.format(row_length, col_length))\n",
    "    row_names = ['Event {0}'.format(n) for n in np.arange(row_length)]\n",
    "    col_names = chars\n",
    "    df = pd.DataFrame(np.zeros((row_length, col_length)), columns=col_names, index=row_names)\n",
    "    \n",
    "    for event_num in range(row_length):\n",
    "        for char_k, val in char_event_dict[event_num].items():\n",
    "            row_label = 'Event {}'.format(event_num)\n",
    "            df.loc[row_label, char_k] += val\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_by_char_one_event(out_df, event_num=0):\n",
    "    char_event_dict = get_chars_from_df(out_df)\n",
    "    row_length = out_df.shape[0]\n",
    "    c = [list(val.keys()) for val in char_event_dict]\n",
    "    chars = list(dict.fromkeys(sum(c,[])))\n",
    "    col_length = len(chars)\n",
    "    row_names = ['Event {0}'.format(n) for n in np.arange(row_length)]\n",
    "    col_names = chars\n",
    "    edf = pd.DataFrame(np.zeros((row_length, col_length)), columns=col_names, index=row_names)\n",
    "    \n",
    "    for char_k, val in char_event_dict[event_num].items():\n",
    "        row_label = 'Event {}'.format(event_num)\n",
    "        edf.loc[row_label, char_k] += val\n",
    "    return edf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_one_event(fn, df, event_num=0):\n",
    "    edf = event_by_char_one_event(df, event_num)\n",
    "    xl = list(edf.columns)\n",
    "    yl = list(edf.index)\n",
    "    plt.figure(figsize=(20,15))\n",
    "    sns.heatmap(edf, xticklabels=xl, yticklabels=yl, cmap=\"BuGn_r\", cbar=False)\n",
    "    plt.savefig(fn, bbox_inches = \"tight\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_events(fn, df):\n",
    "    df = event_by_char_all_events(df)\n",
    "    xl = list(df.columns)\n",
    "    yl = list(df.index)\n",
    "    plt.figure(figsize=(20,15))\n",
    "    sns.heatmap(df, xticklabels=xl, yticklabels=yl, cmap=\"BuGn_r\")\n",
    "    plt.savefig(fn, bbox_inches = \"tight\")   \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save all the pngs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_dir = '../../figures/'\n",
    "movie_name = 'ten_things'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for event_num in range(out_df.shape[0]):\n",
    "    fn = os.path.join(fig_dir, '{0}_event_{1}.png'.format(movie_name, \"{:02d}\".format(event_num)))\n",
    "    plot_one_event(fn, out_df, event_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = os.path.join(fig_dir, '{}_all_events.png'.format(movie_name))\n",
    "plot_all_events(fn, out_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using timecorr for plotting dynamic correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_dynamic_correlations(out_df):\n",
    "\n",
    "    df = event_by_char_all_events(out_df)\n",
    "\n",
    "    mention_matrix = df.values\n",
    "    print('Original matrix has dimensions'.format(mention_matrix.shape))\n",
    "\n",
    "    # specify kernel\n",
    "    width = 3\n",
    "    gaussian = {'name': 'Gaussian', 'weights': tc.gaussian_weights, 'params': {'var': width}}\n",
    "    vec_corrs = tc.timecorr(mention_matrix, weights_function=gaussian['weights'], weights_params=gaussian['params'])\n",
    "\n",
    "    print('vectorized shape : ' + str(np.shape(vec_corrs)))\n",
    "\n",
    "    # use the vec2mat function to convert vectorized correlations to moment-by-moment full correlations\n",
    "    mat_corrs = tc.vec2mat(vec_corrs)\n",
    "\n",
    "    print('matrix shape : ' + str(np.shape(mat_corrs)))\n",
    "    \n",
    "    return mat_corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dyna_mat = get_dynamic_correlations(out_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 49 events and 112 characters\n"
     ]
    }
   ],
   "source": [
    "df = event_by_char_all_events(out_df)\n",
    "char_names = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bianca',\n",
       " 'cameron',\n",
       " 'clint eastwood',\n",
       " 'dakota',\n",
       " 'dart',\n",
       " 'james',\n",
       " 'karen mccullah lutz kirsten smith',\n",
       " 'marley',\n",
       " 'merlot',\n",
       " 'michael',\n",
       " 'north',\n",
       " 'patrick',\n",
       " 'perky',\n",
       " 'semi',\n",
       " 'thirtytwo',\n",
       " 'william shakespeare',\n",
       " 'hemingway',\n",
       " 'kat kat',\n",
       " 'katarina stratford',\n",
       " 'mr',\n",
       " 'ms',\n",
       " 'wrangler',\n",
       " 'kat',\n",
       " 'colette charlotte',\n",
       " 'mandella',\n",
       " 'pat verona',\n",
       " 'joey',\n",
       " 's',\n",
       " 'tragic',\n",
       " 'joyful',\n",
       " 'moms',\n",
       " 'permashitgrin',\n",
       " 'remove',\n",
       " 'sharon',\n",
       " 'viper',\n",
       " 'william',\n",
       " 'jesus',\n",
       " 'mrs',\n",
       " 'sarah lawrence',\n",
       " 'walter nowhere',\n",
       " 'andrew barrett',\n",
       " 'johnson',\n",
       " 'roxanne korrine',\n",
       " 'walter',\n",
       " 'a coffee kid',\n",
       " 'boengie',\n",
       " 'cosia rican',\n",
       " 'scurvy',\n",
       " 'fine',\n",
       " 'janice parker',\n",
       " 'marilyn manson',\n",
       " 'nelson mandela',\n",
       " 'trevor',\n",
       " 'verona',\n",
       " 'woman',\n",
       " 'blaupunkt',\n",
       " 'vintage',\n",
       " 'cells a coffee kid',\n",
       " 'dorsey',\n",
       " 'jock',\n",
       " 'will bogey',\n",
       " 'bogey lowenbraus',\n",
       " 'bogey lowenstein',\n",
       " 'jared leto',\n",
       " 'katarina',\n",
       " 'lou',\n",
       " 'gigglepuss',\n",
       " 'likes thai',\n",
       " 'bruce',\n",
       " 'victorias secret',\n",
       " 'no bikini kill',\n",
       " 'cruella',\n",
       " 'kenneth',\n",
       " 'ninethirty',\n",
       " 'rick',\n",
       " 'gloria steinem',\n",
       " 'levis',\n",
       " 'mandellas',\n",
       " 'padua highs',\n",
       " 'daddy',\n",
       " 'jock a',\n",
       " 'yo clem',\n",
       " 'ziggy',\n",
       " 'ill',\n",
       " 'int',\n",
       " 'queen harry',\n",
       " 'bonchowski',\n",
       " 'wanna',\n",
       " 'clem',\n",
       " 'damn',\n",
       " 'derek ms',\n",
       " 'shakespeare',\n",
       " 'archie',\n",
       " 'betty',\n",
       " 'veronica',\n",
       " 'pat',\n",
       " 'sacrifice',\n",
       " 'wholesome',\n",
       " 'chapin',\n",
       " 'michael sweet',\n",
       " 'cmon',\n",
       " 'start',\n",
       " 'century',\n",
       " 'hearsay',\n",
       " 'love lucy',\n",
       " 'mommy',\n",
       " 'girl',\n",
       " 'molly ringwald',\n",
       " 'fender stratocaster',\n",
       " 'lucentio',\n",
       " 'rises',\n",
       " 'strat']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(char_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('dyna_mat_112_112_49.npy', dyna_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load('dyna_mat_112_112_49.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_dir = '../../figures/'\n",
    "movie_name = 'ten_things'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dyna_mats(out_df, filepath, movie_name):\n",
    "    dyna_mat = get_dynamic_correlations(out_df)\n",
    "    df = event_by_char_all_events(out_df)\n",
    "    char_names = df.columns\n",
    "    for tp in range(dyna_mat.shape[2]):\n",
    "        plt.figure(figsize=(20,15))\n",
    "        sns.set(font_scale = 0.8)\n",
    "        sns.heatmap(dyna_mat[:, :, tp], xticklabels=char_names, yticklabels=char_names, cmap=\"RdBu_r\", vmin=0, vmax=1)\n",
    "        fn = os.path.join(filepath, '{0}_dyna_mat_event_{1}'.format(movie_name, \"{:03d}\".format(tp)))\n",
    "        plt.savefig(fn, bbox_inches = \"tight\")   \n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 49 events and 112 characters\n",
      "Original matrix has dimensions\n",
      "vectorized shape : (49, 6328)\n",
      "matrix shape : (112, 112, 49)\n",
      "We have 49 events and 112 characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vassiki/anaconda2/envs/trial_python3/lib/python3.7/site-packages/ipykernel_launcher.py:6: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "plot_dyna_mats(out_df, fig_dir, movie_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating these figures for all scripts we have analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over all scripts that exist\n",
    "# plot cooccurence over all events\n",
    "# get dynamic correlations for the characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_dir = '../../figures/'\n",
    "root_dir = '../../data/movie_data/'\n",
    "fns = glob.glob(os.path.join(root_dir,'*.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../data/movie_data/s._darko.csv',\n",
       " '../../data/movie_data/10_things_i_hate_about_you.csv',\n",
       " '../../data/movie_data/lord_of_the_rings:_fellowship_of_the_ring,_the.csv',\n",
       " '../../data/movie_data/scott_pilgrim_vs_the_world.csv',\n",
       " '../../data/movie_data/insomnia.csv',\n",
       " '../../data/movie_data/forrest_gump.csv',\n",
       " '../../data/movie_data/grudge,_the.csv',\n",
       " '../../data/movie_data/avatar.csv',\n",
       " '../../data/movie_data/invention_of_lying,_the.csv',\n",
       " '../../data/movie_data/color_of_night.csv',\n",
       " '../../data/movie_data/citizen_kane.csv',\n",
       " '../../data/movie_data/star_wars:_the_phantom_menace.csv',\n",
       " '../../data/movie_data/black_swan.csv',\n",
       " '../../data/movie_data/as_good_as_it_gets.csv',\n",
       " '../../data/movie_data/bourne_identity,_the.csv',\n",
       " '../../data/movie_data/v_for_vendetta.csv',\n",
       " '../../data/movie_data/american_werewolf_in_london.csv',\n",
       " '../../data/movie_data/carrie.csv',\n",
       " '../../data/movie_data/big_white,_the.csv',\n",
       " '../../data/movie_data/2001:_a_space_odyssey.csv']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn =fns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10_things_i_hate_about_you'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn.split('/')[-1].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_num_characters(fn, df):\n",
    "    xdata = np.arange(df.shape[0])\n",
    "    ydata = df.num_characters\n",
    "    xlabel = 'Event Segment'\n",
    "    ylabel = 'Number of Characters'\n",
    "    plt.figure()\n",
    "    sns.lineplot(x=np.arange(df.shape[0]), y=df.num_characters)\n",
    "    plt.savefig(fn, bbox_inches = \"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_num_sentences(fn, df):\n",
    "    xdata = np.arange(df.shape[0])\n",
    "    ydata = df.num_sentences\n",
    "    xlabel = 'Event Segment'\n",
    "    ylabel = 'Number of Sentences'\n",
    "    plt.figure()\n",
    "    sns.lineplot(x=np.arange(df.shape[0]), y=df.num_sentences)\n",
    "    plt.savefig(fn, bbox_inches = \"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plots(fn):\n",
    "    df = pd.read_csv(fn)\n",
    "    movie_title = fn.split('/')[-1].split('.')[0]\n",
    "    print(\"Working on {}\".format(movie_title))\n",
    "    movie_fig_path = os.path.join(fig_dir, movie_title)\n",
    "    if not os.path.exists(movie_fig_path):\n",
    "        os.mkdir(movie_fig_path)\n",
    "    \n",
    "        print(\"Plotting character cooccurence...\")\n",
    "        all_events_cooccurence_fn = os.path.join(movie_fig_path, 'character_cooccurence.png')\n",
    "        plot_all_events(all_events_cooccurence_fn, df)\n",
    "    \n",
    "        print(\"Plotting characters per event...\")\n",
    "        char_event_fn = os.path.join(movie_fig_path, 'num_char_per_event.png')\n",
    "        plot_num_characters(char_event_fn, df)\n",
    "    \n",
    "        print(\"Plotting lines per event...\")\n",
    "        line_event_fn = os.path.join(movie_fig_path, 'num_lines_per_event.png')\n",
    "        plot_num_sentences(line_event_fn, df)\n",
    "    \n",
    "        # dynamic correlations \n",
    "        print(\"Plotting dynamic correlations...\")\n",
    "        dyna_fig_dir = os.path.join(movie_fig_path, 'dyna_plots')\n",
    "        if not os.path.exists(dyna_fig_dir):\n",
    "            os.mkdir(dyna_fig_dir)    \n",
    "        plot_dyna_mats(df, dyna_fig_dir, movie_title)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on s\n",
      "Working on 10_things_i_hate_about_you\n",
      "Plotting character cooccurence...\n",
      "We have 2 events and 71 characters\n",
      "Plotting characters per event...\n",
      "Plotting lines per event...\n",
      "Plotting dynamic correlations...\n",
      "We have 2 events and 71 characters\n",
      "Original matrix has dimensions\n",
      "vectorized shape : (2, 2556)\n",
      "matrix shape : (71, 71, 2)\n",
      "We have 2 events and 71 characters\n",
      "Working on lord_of_the_rings:_fellowship_of_the_ring,_the\n",
      "Plotting character cooccurence...\n",
      "We have 11 events and 44 characters\n",
      "Plotting characters per event...\n",
      "Plotting lines per event...\n",
      "Plotting dynamic correlations...\n",
      "We have 11 events and 44 characters\n",
      "Original matrix has dimensions\n",
      "vectorized shape : (11, 990)\n",
      "matrix shape : (44, 44, 11)\n",
      "We have 11 events and 44 characters\n",
      "Working on scott_pilgrim_vs_the_world\n",
      "Plotting character cooccurence...\n",
      "We have 4 events and 42 characters\n",
      "Plotting characters per event...\n",
      "Plotting lines per event...\n",
      "Plotting dynamic correlations...\n",
      "We have 4 events and 42 characters\n",
      "Original matrix has dimensions\n",
      "vectorized shape : (4, 903)\n",
      "matrix shape : (42, 42, 4)\n",
      "We have 4 events and 42 characters\n",
      "Working on insomnia\n",
      "Working on forrest_gump\n",
      "Plotting character cooccurence...\n",
      "We have 5 events and 47 characters\n",
      "Plotting characters per event...\n",
      "Plotting lines per event...\n",
      "Plotting dynamic correlations...\n",
      "We have 5 events and 47 characters\n",
      "Original matrix has dimensions\n",
      "vectorized shape : (5, 1128)\n",
      "matrix shape : (47, 47, 5)\n",
      "We have 5 events and 47 characters\n",
      "Working on grudge,_the\n",
      "Working on avatar\n",
      "Plotting character cooccurence...\n",
      "We have 7 events and 50 characters\n",
      "Plotting characters per event...\n",
      "Plotting lines per event...\n",
      "Plotting dynamic correlations...\n",
      "We have 7 events and 50 characters\n",
      "Original matrix has dimensions\n",
      "vectorized shape : (7, 1275)\n",
      "matrix shape : (50, 50, 7)\n",
      "We have 7 events and 50 characters\n",
      "Working on invention_of_lying,_the\n",
      "Working on color_of_night\n",
      "Working on citizen_kane\n",
      "Plotting character cooccurence...\n",
      "We have 8 events and 85 characters\n",
      "Plotting characters per event...\n",
      "Plotting lines per event...\n",
      "Plotting dynamic correlations...\n",
      "We have 8 events and 85 characters\n",
      "Original matrix has dimensions\n",
      "vectorized shape : (8, 3655)\n",
      "matrix shape : (85, 85, 8)\n",
      "We have 8 events and 85 characters\n",
      "Working on star_wars:_the_phantom_menace\n",
      "Plotting character cooccurence...\n",
      "We have 13 events and 60 characters\n",
      "Plotting characters per event...\n",
      "Plotting lines per event...\n",
      "Plotting dynamic correlations...\n",
      "We have 13 events and 60 characters\n",
      "Original matrix has dimensions\n",
      "vectorized shape : (13, 1830)\n",
      "matrix shape : (60, 60, 13)\n",
      "We have 13 events and 60 characters\n",
      "Working on black_swan\n",
      "Plotting character cooccurence...\n",
      "We have 12 events and 36 characters\n",
      "Plotting characters per event...\n",
      "Plotting lines per event...\n",
      "Plotting dynamic correlations...\n",
      "We have 12 events and 36 characters\n",
      "Original matrix has dimensions\n",
      "vectorized shape : (12, 666)\n",
      "matrix shape : (36, 36, 12)\n",
      "We have 12 events and 36 characters\n",
      "Working on as_good_as_it_gets\n",
      "Working on bourne_identity,_the\n",
      "Working on v_for_vendetta\n",
      "Plotting character cooccurence...\n",
      "We have 11 events and 54 characters\n",
      "Plotting characters per event...\n",
      "Plotting lines per event...\n",
      "Plotting dynamic correlations...\n",
      "We have 11 events and 54 characters\n",
      "Original matrix has dimensions\n",
      "vectorized shape : (11, 1485)\n",
      "matrix shape : (54, 54, 11)\n",
      "We have 11 events and 54 characters\n",
      "Working on american_werewolf_in_london\n",
      "Plotting character cooccurence...\n",
      "We have 44 events and 69 characters\n",
      "Plotting characters per event...\n",
      "Plotting lines per event...\n",
      "Plotting dynamic correlations...\n",
      "We have 44 events and 69 characters\n",
      "Original matrix has dimensions\n",
      "vectorized shape : (44, 2415)\n",
      "matrix shape : (69, 69, 44)\n",
      "We have 44 events and 69 characters\n",
      "Working on carrie\n",
      "Plotting character cooccurence...\n",
      "We have 51 events and 67 characters\n",
      "Plotting characters per event...\n",
      "Plotting lines per event...\n",
      "Plotting dynamic correlations...\n",
      "We have 51 events and 67 characters\n",
      "Original matrix has dimensions\n",
      "vectorized shape : (51, 2278)\n",
      "matrix shape : (67, 67, 51)\n",
      "We have 51 events and 67 characters\n",
      "Working on big_white,_the\n",
      "Plotting character cooccurence...\n",
      "We have 46 events and 70 characters\n",
      "Plotting characters per event...\n",
      "Plotting lines per event...\n",
      "Plotting dynamic correlations...\n",
      "We have 46 events and 70 characters\n",
      "Original matrix has dimensions\n",
      "vectorized shape : (46, 2485)\n",
      "matrix shape : (70, 70, 46)\n",
      "We have 46 events and 70 characters\n",
      "Working on 2001:_a_space_odyssey\n",
      "Plotting character cooccurence...\n",
      "We have 21 events and 75 characters\n",
      "Plotting characters per event...\n",
      "Plotting lines per event...\n",
      "Plotting dynamic correlations...\n",
      "We have 21 events and 75 characters\n",
      "Original matrix has dimensions\n",
      "vectorized shape : (21, 2850)\n",
      "matrix shape : (75, 75, 21)\n",
      "We have 21 events and 75 characters\n"
     ]
    }
   ],
   "source": [
    "for fn in fns:\n",
    "    create_plots(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gif_paths = glob.glob('../../figures/*/dyna_plots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gifs(gif_path):\n",
    "    name='dynamic_char_corr'\n",
    "\n",
    "    images = []\n",
    "    for file in os.listdir(gif_path):\n",
    "        if file.endswith(\".png\"):\n",
    "            images.append(imageio.imread(os.path.join(gif_path, file)))\n",
    "\n",
    "    \n",
    "    gif_outfile = os.path.join(gif_path, name + '.gif')  \n",
    "    imageio.mimsave(gif_outfile, images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create for ../../figures/invention_of_lying,_the/dyna_plots\n",
      "create for ../../figures/bourne_identity,_the/dyna_plots\n",
      "create for ../../figures/insomnia/dyna_plots\n",
      "create for ../../figures/s/dyna_plots\n",
      "create for ../../figures/as_good_as_it_gets/dyna_plots\n",
      "create for ../../figures/color_of_night/dyna_plots\n",
      "create for ../../figures/grudge,_the/dyna_plots\n"
     ]
    }
   ],
   "source": [
    "for gif_path in gif_paths:\n",
    "    print(\"create for {}\".format(gif_path))\n",
    "    create_gifs(gif_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bash one liner for making gifs across dirs\n",
    "`for x in $( ls -d $root_dir); do convert -delay 10 -loop 0 \"$x\"*.png \"$x\"animation.gif; done`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
