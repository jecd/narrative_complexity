{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fe0d4a51237d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhypertools\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhyp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'joblib'"
     ]
    }
   ],
   "source": [
    "import os, scipy, sklearn, spacy, glob, joblib\n",
    "import requests as req\n",
    "import seaborn as sns\n",
    "import hypertools as hyp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from helpers import *\n",
    "import html2text\n",
    "import markdown\n",
    "from bs4 import BeautifulSoup\n",
    "from scipy.spatial.distance import cdist, pdist, squareform\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from nltk.corpus import stopwords as sw\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileid = '1hCCn31z4HM4IzQi59DP-vvUpYKhlvo2S'\n",
    "datadir = '../data'\n",
    "fname = os.path.join(datadir, 'data_wiped_scripts.csv')\n",
    "\n",
    "if not os.path.exists(datadir):\n",
    "    os.makedirs(datadir)\n",
    "    \n",
    "if not os.path.exists(fname):\n",
    "    print('Fetching file from the interwebz!')\n",
    "    dl(fileid, fname)\n",
    "else:\n",
    "    print('Data found!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(fname, index_col=0)\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = list(data.columns[6:-2])\n",
    "genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_names = pd.read_csv('../data/act_to_char.csv',index_col=0)\n",
    "char_names.head()\n",
    "chars = char_names['char'].tolist()\n",
    "chars = [chars[i].split(sep=' ') for i in range(len(chars))]\n",
    "chars_full = []\n",
    "for char in chars:\n",
    "    for char_bit in char:\n",
    "        chars_full.append(char_bit.lower())\n",
    "exclude = chars_full\n",
    "for word in sw.words('english'):\n",
    "    exclude.extend(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_names = pd.read_csv('../data/act_to_char.csv',index_col=0)\n",
    "char_names.head()\n",
    "chars = char_names['char'].tolist()\n",
    "chars = [chars[i].split(sep=' ') for i in range(len(chars))]\n",
    "chars_full = []\n",
    "for char in chars:\n",
    "    for char_bit in char:\n",
    "        chars_full.append(char_bit.lower())\n",
    "exclude = chars_full\n",
    "for word in sw.words('english'):\n",
    "    exclude.extend(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(**vectorizer_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = cv.fit_transform(corpus)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
